{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49167030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedModelTrainer:\n",
    "    def __init__(self, db_config, model_save_dir='enhanced_models'):\n",
    "        self.db_config = db_config\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.setup_logging()\n",
    "        self.create_model_directory()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler('enhanced_model_training.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def create_model_directory(self):\n",
    "        if not os.path.exists(self.model_save_dir):\n",
    "            os.makedirs(self.model_save_dir)\n",
    "            self.logger.info(f\"Created model directory: {self.model_save_dir}\")\n",
    "    \n",
    "    def connect_db(self):\n",
    "        try:\n",
    "            conn = mysql.connector.connect(**self.db_config)\n",
    "            return conn\n",
    "        except mysql.connector.Error as e:\n",
    "            self.logger.error(f\"Database connection error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_directional_accuracy(self, y_true, y_pred):\n",
    "        \"\"\"Calculate percentage of correct directional predictions\"\"\"\n",
    "        # For % change predictions, direction is simply the sign\n",
    "        true_direction = y_true > 0\n",
    "        pred_direction = y_pred > 0\n",
    "        \n",
    "        correct = np.sum(true_direction == pred_direction)\n",
    "        accuracy = (correct / len(true_direction)) * 100\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred, is_percentage=True):\n",
    "        \"\"\"Calculate performance metrics\"\"\"\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        # RÂ² can be negative, so we'll track it but not use it as primary metric\n",
    "        try:\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "        except:\n",
    "            r2 = -999\n",
    "        \n",
    "        dir_acc = self.calculate_directional_accuracy(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2_score': r2,\n",
    "            'directional_accuracy': dir_acc\n",
    "        }\n",
    "    \n",
    "    def train_random_forest_tuned(self, X_train, y_train, X_test, y_test, quick_tune=False):\n",
    "        \"\"\"Train Random Forest with hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"Training Random Forest with tuning...\")\n",
    "        \n",
    "        if quick_tune:\n",
    "            # Quick tuning for faster iteration\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [15, 25],\n",
    "                'min_samples_split': [3, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            }\n",
    "        else:\n",
    "            # Comprehensive tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [10, 20, 30, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            }\n",
    "        \n",
    "        rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "        \n",
    "        # Use RandomizedSearchCV for speed\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            rf, param_grid, n_iter=10, cv=3, \n",
    "            scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        metrics = self.calculate_metrics(y_test, y_pred)\n",
    "        \n",
    "        self.logger.info(f\"Best RF params: {grid_search.best_params_}\")\n",
    "        \n",
    "        return best_model, y_pred, metrics\n",
    "    \n",
    "    def train_xgboost_tuned(self, X_train, y_train, X_test, y_test, quick_tune=False):\n",
    "        \"\"\"Train XGBoost with hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"Training XGBoost with tuning...\")\n",
    "        \n",
    "        if quick_tune:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [6, 10],\n",
    "                'learning_rate': [0.05, 0.1],\n",
    "                'subsample': [0.8]\n",
    "            }\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [5, 7, 10, 15],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'subsample': [0.7, 0.8, 0.9],\n",
    "                'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "            }\n",
    "        \n",
    "        xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "        \n",
    "        grid_search = RandomizedSearchCV(\n",
    "            xgb_model, param_grid, n_iter=10, cv=3,\n",
    "            scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        metrics = self.calculate_metrics(y_test, y_pred)\n",
    "        \n",
    "        self.logger.info(f\"Best XGB params: {grid_search.best_params_}\")\n",
    "        \n",
    "        return best_model, y_pred, metrics\n",
    "    \n",
    "    def train_mlp_tuned(self, X_train, y_train, X_test, y_test, quick_tune=False):\n",
    "        \"\"\"Train MLP with hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"Training MLP with tuning...\")\n",
    "        \n",
    "        if quick_tune:\n",
    "            param_grid = {\n",
    "                'hidden_layer_sizes': [(100,), (100, 50)],\n",
    "                'alpha': [0.0001, 0.001],\n",
    "                'learning_rate_init': [0.001]\n",
    "            }\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100), (150, 75)],\n",
    "                'alpha': [0.0001, 0.001, 0.01],\n",
    "                'learning_rate_init': [0.001, 0.01]\n",
    "            }\n",
    "        \n",
    "        mlp = MLPRegressor(\n",
    "            max_iter=1000, early_stopping=True, \n",
    "            validation_fraction=0.1, random_state=42\n",
    "        )\n",
    "        \n",
    "        grid_search = RandomizedSearchCV(\n",
    "            mlp, param_grid, n_iter=8, cv=3,\n",
    "            scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        metrics = self.calculate_metrics(y_test, y_pred)\n",
    "        \n",
    "        self.logger.info(f\"Best MLP params: {grid_search.best_params_}\")\n",
    "        \n",
    "        return best_model, y_pred, metrics\n",
    "    \n",
    "    def train_lasso_tuned(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train Lasso with hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"Training Lasso with tuning...\")\n",
    "        \n",
    "        param_grid = {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "        }\n",
    "        \n",
    "        lasso = Lasso(max_iter=5000, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            lasso, param_grid, cv=3,\n",
    "            scoring='neg_mean_squared_error', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        metrics = self.calculate_metrics(y_test, y_pred)\n",
    "        \n",
    "        self.logger.info(f\"Best Lasso alpha: {grid_search.best_params_['alpha']}\")\n",
    "        \n",
    "        return best_model, y_pred, metrics\n",
    "    \n",
    "    def train_ridge_tuned(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train Ridge Regression with hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"Training Ridge with tuning...\")\n",
    "        \n",
    "        param_grid = {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "        \n",
    "        ridge = Ridge(max_iter=5000, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            ridge, param_grid, cv=3,\n",
    "            scoring='neg_mean_squared_error', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        metrics = self.calculate_metrics(y_test, y_pred)\n",
    "        \n",
    "        self.logger.info(f\"Best Ridge alpha: {grid_search.best_params_['alpha']}\")\n",
    "        \n",
    "        return best_model, y_pred, metrics\n",
    "    \n",
    "    def train_arima(self, y_train, y_test):\n",
    "        \"\"\"Train ARIMA model (no hyperparameter tuning for now)\"\"\"\n",
    "        self.logger.info(\"Training ARIMA...\")\n",
    "        \n",
    "        try:\n",
    "            model = ARIMA(y_train, order=(2, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            \n",
    "            forecast = fitted_model.forecast(steps=len(y_test))\n",
    "            y_pred = np.array(forecast)\n",
    "            \n",
    "            metrics = self.calculate_metrics(y_test, y_pred)\n",
    "            \n",
    "            return fitted_model, y_pred, metrics\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ARIMA training failed: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def save_model(self, model, symbol, model_type):\n",
    "        \"\"\"Save trained model to disk\"\"\"\n",
    "        filename = f\"{symbol}_{model_type}_enhanced.pkl\"\n",
    "        filepath = os.path.join(self.model_save_dir, filename)\n",
    "        joblib.dump(model, filepath)\n",
    "        return filepath\n",
    "    \n",
    "    def save_performance_to_db(self, symbol, model_type, metrics, train_samples, \n",
    "                               test_samples, feature_count, model_path, has_sentiment):\n",
    "        \"\"\"Save model performance metrics to database\"\"\"\n",
    "        conn = self.connect_db()\n",
    "        if not conn:\n",
    "            return False\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Use existing model_performance table\n",
    "        query = \"\"\"\n",
    "        INSERT INTO model_performance \n",
    "        (symbol, model_type, rmse, mae, r2_score, directional_accuracy,\n",
    "         train_samples, test_samples, feature_count, model_path)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        \n",
    "        model_type_label = f\"{model_type}_Enhanced_{'Sentiment' if has_sentiment else 'NoSentiment'}\"\n",
    "        \n",
    "        values = (\n",
    "            symbol,\n",
    "            model_type_label,\n",
    "            metrics['rmse'],\n",
    "            metrics['mae'],\n",
    "            metrics['r2_score'],\n",
    "            metrics['directional_accuracy'],\n",
    "            train_samples,\n",
    "            test_samples,\n",
    "            feature_count,\n",
    "            model_path\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "            return True\n",
    "        except mysql.connector.Error as e:\n",
    "            self.logger.error(f\"Error saving performance: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "    \n",
    "    def train_all_models(self, stock_data, quick_tune=True):\n",
    "        \"\"\"\n",
    "        Train all models with hyperparameter tuning\n",
    "        quick_tune: If True, use faster parameter grids\n",
    "        \"\"\"\n",
    "        symbol = stock_data['symbol']\n",
    "        X_train = stock_data['X_train']\n",
    "        X_test = stock_data['X_test']\n",
    "        y_train = stock_data['y_train']\n",
    "        y_test = stock_data['y_test']\n",
    "        has_sentiment = stock_data.get('has_sentiment', False)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. Random Forest (Tuned)\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_random_forest_tuned(\n",
    "                X_train, y_train, X_test, y_test, quick_tune\n",
    "            )\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'RandomForest')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'RandomForest', metrics,\n",
    "                    len(X_train), len(X_test), X_train.shape[1], model_path, has_sentiment\n",
    "                )\n",
    "                results['RandomForest'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Random Forest failed for {symbol}: {e}\")\n",
    "        \n",
    "        # 2. XGBoost (Tuned)\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_xgboost_tuned(\n",
    "                X_train, y_train, X_test, y_test, quick_tune\n",
    "            )\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'XGBoost')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'XGBoost', metrics,\n",
    "                    len(X_train), len(X_test), X_train.shape[1], model_path, has_sentiment\n",
    "                )\n",
    "                results['XGBoost'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"XGBoost failed for {symbol}: {e}\")\n",
    "        \n",
    "        # 3. MLP (Tuned)\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_mlp_tuned(\n",
    "                X_train, y_train, X_test, y_test, quick_tune\n",
    "            )\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'MLP')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'MLP', metrics,\n",
    "                    len(X_train), len(X_test), X_train.shape[1], model_path, has_sentiment\n",
    "                )\n",
    "                results['MLP'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"MLP failed for {symbol}: {e}\")\n",
    "        \n",
    "        # 4. Lasso (Tuned)\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_lasso_tuned(X_train, y_train, X_test, y_test)\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'Lasso')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'Lasso', metrics,\n",
    "                    len(X_train), len(X_test), X_train.shape[1], model_path, has_sentiment\n",
    "                )\n",
    "                results['Lasso'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Lasso failed for {symbol}: {e}\")\n",
    "        \n",
    "        # 5. Ridge (Tuned) - NEW\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_ridge_tuned(X_train, y_train, X_test, y_test)\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'Ridge')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'Ridge', metrics,\n",
    "                    len(X_train), len(X_test), X_train.shape[1], model_path, has_sentiment\n",
    "                )\n",
    "                results['Ridge'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ridge failed for {symbol}: {e}\")\n",
    "        \n",
    "        # 6. ARIMA\n",
    "        try:\n",
    "            model, y_pred, metrics = self.train_arima(y_train, y_test)\n",
    "            if model:\n",
    "                model_path = self.save_model(model, symbol, 'ARIMA')\n",
    "                self.save_performance_to_db(\n",
    "                    symbol, 'ARIMA', metrics,\n",
    "                    len(y_train), len(y_test), 0, model_path, has_sentiment\n",
    "                )\n",
    "                results['ARIMA'] = {'model': model, 'metrics': metrics, 'predictions': y_pred}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ARIMA failed for {symbol}: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def select_best_model(self, symbol, results):\n",
    "        \"\"\"Select best model based on directional accuracy (primary) and RMSE (secondary)\"\"\"\n",
    "        if not results:\n",
    "            self.logger.warning(f\"No valid models for {symbol}\")\n",
    "            return None\n",
    "        \n",
    "        # Sort by directional accuracy first, then RMSE\n",
    "        sorted_models = sorted(\n",
    "            results.items(),\n",
    "            key=lambda x: (-x[1]['metrics']['directional_accuracy'], x[1]['metrics']['rmse'])\n",
    "        )\n",
    "        \n",
    "        best_model_type = sorted_models[0][0]\n",
    "        best_metrics = sorted_models[0][1]['metrics']\n",
    "        best_model_path = f\"{self.model_save_dir}/{symbol}_{best_model_type}_enhanced.pkl\"\n",
    "        \n",
    "        # Save selection to database\n",
    "        conn = self.connect_db()\n",
    "        if not conn:\n",
    "            return None\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = \"\"\"\n",
    "        INSERT INTO model_selection (symbol, selected_model_type, model_path, rmse, notes)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            selected_model_type = VALUES(selected_model_type),\n",
    "            model_path = VALUES(model_path),\n",
    "            rmse = VALUES(rmse),\n",
    "            selection_date = CURRENT_TIMESTAMP,\n",
    "            notes = VALUES(notes)\n",
    "        \"\"\"\n",
    "        \n",
    "        notes = f\"Enhanced model. Dir Acc: {best_metrics['directional_accuracy']:.1f}%, RMSE: {best_metrics['rmse']:.2f}%\"\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(query, (symbol, best_model_type + '_Enhanced', best_model_path, \n",
    "                                  best_metrics['rmse'], notes))\n",
    "            conn.commit()\n",
    "            self.logger.info(f\"{symbol}: Selected {best_model_type} \"\n",
    "                           f\"(Dir Acc={best_metrics['directional_accuracy']:.1f}%, \"\n",
    "                           f\"RMSE={best_metrics['rmse']:.2f}%)\")\n",
    "        except mysql.connector.Error as e:\n",
    "            self.logger.error(f\"Error saving model selection: {e}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "        \n",
    "        return best_model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04f5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Enhanced Model Trainer initialized\n",
      "â Will train with hyperparameter tuning\n",
      "â Target: Price Change % (better for directional accuracy)\n"
     ]
    }
   ],
   "source": [
    "db_config = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'trading_system'\n",
    "}\n",
    "\n",
    "enhanced_trainer = EnhancedModelTrainer(db_config)\n",
    "print(\"â Enhanced Model Trainer initialized\")\n",
    "print(\"â Will train with hyperparameter tuning\")\n",
    "print(\"â Target: Price Change % (better for directional accuracy)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914e7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Loaded data for 24 stocks\n"
     ]
    }
   ],
   "source": [
    "# Load prepared data\n",
    "import pickle\n",
    "\n",
    "with open('enhanced_stock_data.pkl', 'rb') as f:\n",
    "    enhanced_stock_data = pickle.load(f)\n",
    "\n",
    "print(f\"â Loaded data for {len(enhanced_stock_data)} stocks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74cb3152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:07:47,785 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing enhanced model training on AAPL...\n",
      "============================================================\n",
      "Training 6 tuned models for AAPL...\n",
      "This will take 5-10 minutes due to hyperparameter tuning...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:14:23,052 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 03:14:23,568 - INFO - package: mysql.connector.plugins\n",
      "2025-10-09 03:14:23,571 - INFO - plugin_name: caching_sha2_password\n",
      "2025-10-09 03:14:23,573 - INFO - AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin\n",
      "2025-10-09 03:14:23,655 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 03:21:32,225 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "2025-10-09 03:21:32,592 - INFO - Training MLP with tuning...\n",
      "2025-10-09 03:21:37,344 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 03:21:37,532 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 03:21:46,541 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 03:21:46,727 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 03:21:47,209 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 03:21:47,443 - INFO - Training ARIMA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Model Performance:\n",
      "----------------------------------------------------------------------\n",
      "Model           RMSE (%)     MAE (%)      Dir Acc     \n",
      "----------------------------------------------------------------------\n",
      "RandomForest       1.516%       1.047%        65.8%\n",
      "XGBoost            1.593%       1.158%        46.8%\n",
      "MLP                1.816%       1.385%        55.7%\n",
      "Lasso              1.480%       1.035%        57.0%\n",
      "Ridge              2.885%       2.255%        41.8%\n",
      "ARIMA              1.480%       1.032%        58.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:21:48,638 - INFO - AAPL: Selected RandomForest (Dir Acc=65.8%, RMSE=1.52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â Best model for AAPL: RandomForest\n",
      "â Directional Accuracy: 65.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting enhanced model training on AAPL...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_symbol = 'AAPL'\n",
    "if test_symbol in enhanced_stock_data:\n",
    "    print(f\"Training 6 tuned models for {test_symbol}...\")\n",
    "    print(\"This will take 5-10 minutes due to hyperparameter tuning...\\n\")\n",
    "    \n",
    "    results = enhanced_trainer.train_all_models(enhanced_stock_data[test_symbol], quick_tune=True)\n",
    "    \n",
    "    print(\"\\nEnhanced Model Performance:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Model':<15} {'RMSE (%)':<12} {'MAE (%)':<12} {'Dir Acc':<12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for model_type, data in results.items():\n",
    "        metrics = data['metrics']\n",
    "        print(f\"{model_type:<15} {metrics['rmse']:>8.3f}%    \"\n",
    "              f\"{metrics['mae']:>8.3f}%    \"\n",
    "              f\"{metrics['directional_accuracy']:>8.1f}%\")\n",
    "    \n",
    "    best = enhanced_trainer.select_best_model(test_symbol, results)\n",
    "    print(f\"\\nâ Best model for {test_symbol}: {best}\")\n",
    "    print(f\"â Directional Accuracy: {results[best]['metrics']['directional_accuracy']:.1f}%\")\n",
    "else:\n",
    "    print(f\"No data available for {test_symbol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b98fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:33:33,676 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training enhanced models for all stocks with hyperparameter tuning...\n",
      "This will take 30-60 minutes depending on your CPU\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/24] Training models for AAPL...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:40:00,883 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 03:40:01,285 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 03:46:24,759 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "2025-10-09 03:46:24,891 - INFO - Training MLP with tuning...\n",
      "2025-10-09 03:46:28,366 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 03:46:28,453 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 03:46:31,999 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 03:46:32,106 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 03:46:32,500 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 03:46:32,601 - INFO - Training ARIMA...\n",
      "2025-10-09 03:46:32,993 - INFO - AAPL: Selected RandomForest (Dir Acc=65.8%, RMSE=1.52%)\n",
      "2025-10-09 03:46:33,006 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.52% | Dir Acc:  65.8%\n",
      "  XGBoost      | RMSE:   1.59% | Dir Acc:  46.8%\n",
      "  MLP          | RMSE:   1.82% | Dir Acc:  55.7%\n",
      "  Lasso        | RMSE:   1.48% | Dir Acc:  57.0%\n",
      "  Ridge        | RMSE:   2.89% | Dir Acc:  41.8%\n",
      "  ARIMA        | RMSE:   1.48% | Dir Acc:  58.2%\n",
      "  â Best: RandomForest (Dir Acc: 65.8%)\n",
      "\n",
      "[2/24] Training models for AMD...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 03:51:50,149 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 03:51:50,294 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 03:58:53,934 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 03:58:54,123 - INFO - Training MLP with tuning...\n",
      "2025-10-09 03:58:57,296 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 03:58:57,467 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 03:59:07,266 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 03:59:07,519 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 03:59:07,961 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 03:59:08,161 - INFO - Training ARIMA...\n",
      "2025-10-09 03:59:09,053 - INFO - AMD: Selected Ridge (Dir Acc=46.8%, RMSE=4.17%)\n",
      "2025-10-09 03:59:09,063 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.99% | Dir Acc:  41.8%\n",
      "  XGBoost      | RMSE:   3.02% | Dir Acc:  44.3%\n",
      "  MLP          | RMSE:   3.24% | Dir Acc:  44.3%\n",
      "  Lasso        | RMSE:   2.76% | Dir Acc:  44.3%\n",
      "  Ridge        | RMSE:   4.17% | Dir Acc:  46.8%\n",
      "  ARIMA        | RMSE:   2.76% | Dir Acc:  43.0%\n",
      "  â Best: Ridge (Dir Acc: 46.8%)\n",
      "\n",
      "[3/24] Training models for AMZN...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 04:04:55,159 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 15}\n",
      "2025-10-09 04:04:55,448 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 11:29:49,406 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 11:29:49,830 - INFO - Training MLP with tuning...\n",
      "2025-10-09 11:29:52,335 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 11:29:52,504 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 11:29:56,527 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 11:29:56,620 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 11:29:57,022 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 11:29:57,114 - INFO - Training ARIMA...\n",
      "2025-10-09 11:29:57,689 - INFO - AMZN: Selected ARIMA (Dir Acc=53.2%, RMSE=1.71%)\n",
      "2025-10-09 11:29:57,692 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.69% | Dir Acc:  50.6%\n",
      "  XGBoost      | RMSE:   1.65% | Dir Acc:  50.6%\n",
      "  MLP          | RMSE:   1.91% | Dir Acc:  49.4%\n",
      "  Lasso        | RMSE:   1.71% | Dir Acc:  53.2%\n",
      "  Ridge        | RMSE:   2.63% | Dir Acc:  49.4%\n",
      "  ARIMA        | RMSE:   1.71% | Dir Acc:  53.2%\n",
      "  â Best: ARIMA (Dir Acc: 53.2%)\n",
      "\n",
      "[4/24] Training models for BLK...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:35:40,464 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 11:35:40,692 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 11:41:05,165 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 11:41:05,297 - INFO - Training MLP with tuning...\n",
      "2025-10-09 11:41:08,565 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 11:41:08,674 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 11:41:11,602 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 11:41:11,706 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 11:41:12,051 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 11:41:12,131 - INFO - Training ARIMA...\n",
      "2025-10-09 11:41:12,709 - INFO - BLK: Selected Ridge (Dir Acc=59.5%, RMSE=1.60%)\n",
      "2025-10-09 11:41:12,710 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.82% | Dir Acc:  45.6%\n",
      "  XGBoost      | RMSE:   1.68% | Dir Acc:  50.6%\n",
      "  MLP          | RMSE:   1.67% | Dir Acc:  57.0%\n",
      "  Lasso        | RMSE:   1.34% | Dir Acc:  54.4%\n",
      "  Ridge        | RMSE:   1.60% | Dir Acc:  59.5%\n",
      "  ARIMA        | RMSE:   1.34% | Dir Acc:  54.4%\n",
      "  â Best: Ridge (Dir Acc: 59.5%)\n",
      "\n",
      "[5/24] Training models for CHN...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:46:34,071 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 11:46:34,179 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 11:52:09,737 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 11:52:09,924 - INFO - Training MLP with tuning...\n",
      "2025-10-09 11:52:14,594 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 11:52:14,779 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 11:52:23,983 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 11:52:24,168 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 11:52:24,647 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 11:52:24,806 - INFO - Training ARIMA...\n",
      "2025-10-09 11:52:25,733 - INFO - CHN: Selected Lasso (Dir Acc=62.0%, RMSE=1.57%)\n",
      "2025-10-09 11:52:25,737 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   4.07% | Dir Acc:  34.2%\n",
      "  XGBoost      | RMSE:   2.82% | Dir Acc:  34.2%\n",
      "  MLP          | RMSE:   3.33% | Dir Acc:  41.8%\n",
      "  Lasso        | RMSE:   1.57% | Dir Acc:  62.0%\n",
      "  Ridge        | RMSE:   6.38% | Dir Acc:  32.9%\n",
      "  ARIMA        | RMSE:   1.57% | Dir Acc:  62.0%\n",
      "  â Best: Lasso (Dir Acc: 62.0%)\n",
      "\n",
      "[6/24] Training models for ERO...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:59:07,498 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 11:59:07,768 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 12:06:00,577 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 12:06:00,889 - INFO - Training MLP with tuning...\n",
      "2025-10-09 12:06:03,994 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 12:06:04,222 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 12:06:15,400 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 12:06:15,592 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 12:06:16,126 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 12:06:16,296 - INFO - Training ARIMA...\n",
      "2025-10-09 12:06:17,414 - INFO - ERO: Selected RandomForest (Dir Acc=62.0%, RMSE=2.86%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.86% | Dir Acc:  62.0%\n",
      "  XGBoost      | RMSE:   2.86% | Dir Acc:  60.8%\n",
      "  MLP          | RMSE:   3.32% | Dir Acc:  43.0%\n",
      "  Lasso        | RMSE:   2.94% | Dir Acc:  57.0%\n",
      "  Ridge        | RMSE:   6.55% | Dir Acc:  45.6%\n",
      "  ARIMA        | RMSE:   2.94% | Dir Acc:  57.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 12:06:17,419 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â Best: RandomForest (Dir Acc: 62.0%)\n",
      "\n",
      "[7/24] Training models for FXP...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 12:14:01,421 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 12:14:01,722 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 14:22:32,022 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 14:22:32,192 - INFO - Training MLP with tuning...\n",
      "2025-10-09 14:22:42,592 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 50), 'alpha': 0.001}\n",
      "2025-10-09 14:22:42,710 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 14:23:02,100 - INFO - Best Lasso alpha: 10.0\n",
      "2025-10-09 14:23:02,236 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 14:23:02,801 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 14:23:02,922 - INFO - Training ARIMA...\n",
      "2025-10-09 14:23:03,514 - INFO - FXP: Selected MLP (Dir Acc=60.8%, RMSE=3.53%)\n",
      "2025-10-09 14:23:03,516 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   6.24% | Dir Acc:  41.8%\n",
      "  XGBoost      | RMSE:   4.72% | Dir Acc:  43.0%\n",
      "  MLP          | RMSE:   3.53% | Dir Acc:  60.8%\n",
      "  Lasso        | RMSE:   2.22% | Dir Acc:  57.0%\n",
      "  Ridge        | RMSE:   4.99% | Dir Acc:  54.4%\n",
      "  ARIMA        | RMSE:   2.22% | Dir Acc:  57.0%\n",
      "  â Best: MLP (Dir Acc: 60.8%)\n",
      "\n",
      "[8/24] Training models for GOOGL...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 14:28:38,525 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 14:28:38,694 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 14:33:40,566 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 14:33:40,715 - INFO - Training MLP with tuning...\n",
      "2025-10-09 14:33:43,056 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 14:33:43,151 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 14:33:49,124 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 14:33:49,231 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 14:33:49,677 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 14:33:49,773 - INFO - Training ARIMA...\n",
      "2025-10-09 14:33:50,363 - INFO - GOOGL: Selected Ridge (Dir Acc=59.5%, RMSE=3.37%)\n",
      "2025-10-09 14:33:50,363 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.13% | Dir Acc:  48.1%\n",
      "  XGBoost      | RMSE:   1.94% | Dir Acc:  48.1%\n",
      "  MLP          | RMSE:   2.25% | Dir Acc:  41.8%\n",
      "  Lasso        | RMSE:   1.69% | Dir Acc:  58.2%\n",
      "  Ridge        | RMSE:   3.37% | Dir Acc:  59.5%\n",
      "  ARIMA        | RMSE:   1.69% | Dir Acc:  58.2%\n",
      "  â Best: Ridge (Dir Acc: 59.5%)\n",
      "\n",
      "[9/24] Training models for GXC...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 14:39:45,644 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 14:39:45,769 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 14:44:17,347 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 14:44:17,440 - INFO - Training MLP with tuning...\n",
      "2025-10-09 14:44:20,320 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 14:44:20,377 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 14:44:23,512 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 14:44:23,578 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 14:44:23,828 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 14:44:23,896 - INFO - Training ARIMA...\n",
      "2025-10-09 14:44:24,129 - INFO - GXC: Selected Lasso (Dir Acc=59.5%, RMSE=1.07%)\n",
      "2025-10-09 14:44:24,129 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   3.44% | Dir Acc:  41.8%\n",
      "  XGBoost      | RMSE:   2.21% | Dir Acc:  43.0%\n",
      "  MLP          | RMSE:   1.30% | Dir Acc:  48.1%\n",
      "  Lasso        | RMSE:   1.07% | Dir Acc:  59.5%\n",
      "  Ridge        | RMSE:   2.17% | Dir Acc:  46.8%\n",
      "  ARIMA        | RMSE:   1.08% | Dir Acc:  59.5%\n",
      "  â Best: Lasso (Dir Acc: 59.5%)\n",
      "\n",
      "[10/24] Training models for JPM...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 14:50:02,283 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 14:50:02,376 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 14:54:31,666 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 14:54:31,780 - INFO - Training MLP with tuning...\n",
      "2025-10-09 14:54:35,768 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 14:54:35,815 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 14:54:39,216 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 14:54:39,308 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 14:54:39,587 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 14:54:39,637 - INFO - Training ARIMA...\n",
      "2025-10-09 14:54:39,886 - INFO - JPM: Selected MLP (Dir Acc=64.6%, RMSE=1.28%)\n",
      "2025-10-09 14:54:39,888 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.94% | Dir Acc:  40.5%\n",
      "  XGBoost      | RMSE:   1.31% | Dir Acc:  48.1%\n",
      "  MLP          | RMSE:   1.28% | Dir Acc:  64.6%\n",
      "  Lasso        | RMSE:   1.07% | Dir Acc:  60.8%\n",
      "  Ridge        | RMSE:   2.57% | Dir Acc:  43.0%\n",
      "  ARIMA        | RMSE:   1.07% | Dir Acc:  60.8%\n",
      "  â Best: MLP (Dir Acc: 64.6%)\n",
      "\n",
      "[11/24] Training models for KR...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 14:59:45,386 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 14:59:45,552 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 15:05:48,918 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 15:05:49,160 - INFO - Training MLP with tuning...\n",
      "2025-10-09 15:05:54,282 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 15:05:54,469 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 15:06:02,730 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 15:06:02,872 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 15:06:03,318 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 15:06:03,459 - INFO - Training ARIMA...\n",
      "2025-10-09 15:06:04,123 - INFO - KR: Selected Ridge (Dir Acc=62.0%, RMSE=2.42%)\n",
      "2025-10-09 15:06:04,128 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.69% | Dir Acc:  60.8%\n",
      "  XGBoost      | RMSE:   1.70% | Dir Acc:  54.4%\n",
      "  MLP          | RMSE:   2.09% | Dir Acc:  51.9%\n",
      "  Lasso        | RMSE:   1.68% | Dir Acc:  49.4%\n",
      "  Ridge        | RMSE:   2.42% | Dir Acc:  62.0%\n",
      "  ARIMA        | RMSE:   1.68% | Dir Acc:  49.4%\n",
      "  â Best: Ridge (Dir Acc: 62.0%)\n",
      "\n",
      "[12/24] Training models for MDT...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:11:36,491 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 15:11:36,691 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 15:16:29,162 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 15:16:29,263 - INFO - Training MLP with tuning...\n",
      "2025-10-09 15:16:32,181 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 15:16:32,227 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 15:16:35,035 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 15:16:35,098 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 15:16:35,349 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 15:16:35,409 - INFO - Training ARIMA...\n",
      "2025-10-09 15:16:35,712 - INFO - MDT: Selected Lasso (Dir Acc=57.0%, RMSE=1.11%)\n",
      "2025-10-09 15:16:35,712 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.19% | Dir Acc:  49.4%\n",
      "  XGBoost      | RMSE:   1.63% | Dir Acc:  49.4%\n",
      "  MLP          | RMSE:   1.46% | Dir Acc:  49.4%\n",
      "  Lasso        | RMSE:   1.11% | Dir Acc:  57.0%\n",
      "  Ridge        | RMSE:   1.69% | Dir Acc:  46.8%\n",
      "  ARIMA        | RMSE:   1.11% | Dir Acc:  57.0%\n",
      "  â Best: Lasso (Dir Acc: 57.0%)\n",
      "\n",
      "[13/24] Training models for META...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:21:59,054 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 15:21:59,232 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 15:27:37,342 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "2025-10-09 15:27:37,558 - INFO - Training MLP with tuning...\n",
      "2025-10-09 15:27:40,671 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 15:27:40,758 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 15:27:45,084 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 15:27:45,151 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 15:27:45,407 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 15:27:45,457 - INFO - Training ARIMA...\n",
      "2025-10-09 15:27:45,700 - INFO - META: Selected MLP (Dir Acc=54.4%, RMSE=2.99%)\n",
      "2025-10-09 15:27:45,707 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.22% | Dir Acc:  46.8%\n",
      "  XGBoost      | RMSE:   3.19% | Dir Acc:  50.6%\n",
      "  MLP          | RMSE:   2.99% | Dir Acc:  54.4%\n",
      "  Lasso        | RMSE:   1.90% | Dir Acc:  44.3%\n",
      "  Ridge        | RMSE:   3.99% | Dir Acc:  53.2%\n",
      "  ARIMA        | RMSE:   1.89% | Dir Acc:  44.3%\n",
      "  â Best: MLP (Dir Acc: 54.4%)\n",
      "\n",
      "[14/24] Training models for MSFT...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:34:24,598 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 15:34:24,770 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 15:41:03,055 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "2025-10-09 15:41:03,276 - INFO - Training MLP with tuning...\n",
      "2025-10-09 15:41:06,775 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 15:41:06,880 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 15:41:10,157 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 15:41:10,244 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 15:41:10,630 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 15:41:10,695 - INFO - Training ARIMA...\n",
      "2025-10-09 15:41:11,085 - INFO - MSFT: Selected Lasso (Dir Acc=54.4%, RMSE=0.99%)\n",
      "2025-10-09 15:41:11,087 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.12% | Dir Acc:  45.6%\n",
      "  XGBoost      | RMSE:   1.30% | Dir Acc:  43.0%\n",
      "  MLP          | RMSE:   4.29% | Dir Acc:  43.0%\n",
      "  Lasso        | RMSE:   0.99% | Dir Acc:  54.4%\n",
      "  Ridge        | RMSE:   8.61% | Dir Acc:  45.6%\n",
      "  ARIMA        | RMSE:   0.99% | Dir Acc:  54.4%\n",
      "  â Best: Lasso (Dir Acc: 54.4%)\n",
      "\n",
      "[15/24] Training models for NFLX...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:46:05,846 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 15:46:05,988 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 15:51:06,688 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 15:51:06,841 - INFO - Training MLP with tuning...\n",
      "2025-10-09 15:51:10,418 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 15:51:10,557 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 15:51:15,203 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 15:51:15,300 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 15:51:15,598 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 15:51:15,690 - INFO - Training ARIMA...\n",
      "2025-10-09 15:51:16,243 - INFO - NFLX: Selected Ridge (Dir Acc=50.6%, RMSE=2.62%)\n",
      "2025-10-09 15:51:16,245 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.21% | Dir Acc:  40.5%\n",
      "  XGBoost      | RMSE:   1.81% | Dir Acc:  49.4%\n",
      "  MLP          | RMSE:   1.82% | Dir Acc:  43.0%\n",
      "  Lasso        | RMSE:   1.57% | Dir Acc:  48.1%\n",
      "  Ridge        | RMSE:   2.62% | Dir Acc:  50.6%\n",
      "  ARIMA        | RMSE:   1.57% | Dir Acc:  48.1%\n",
      "  â Best: Ridge (Dir Acc: 50.6%)\n",
      "\n",
      "[16/24] Training models for NVDA...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:58:28,284 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 15}\n",
      "2025-10-09 15:58:28,625 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:05:12,109 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 16:05:12,677 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:05:17,765 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 16:05:17,951 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:05:26,412 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 16:05:26,604 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:05:27,140 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:05:27,303 - INFO - Training ARIMA...\n",
      "2025-10-09 16:05:28,571 - INFO - NVDA: Selected ARIMA (Dir Acc=58.2%, RMSE=1.73%)\n",
      "2025-10-09 16:05:28,587 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   3.35% | Dir Acc:  44.3%\n",
      "  XGBoost      | RMSE:   5.76% | Dir Acc:  41.8%\n",
      "  MLP          | RMSE:   5.05% | Dir Acc:  49.4%\n",
      "  Lasso        | RMSE:   1.74% | Dir Acc:  58.2%\n",
      "  Ridge        | RMSE:  11.70% | Dir Acc:  45.6%\n",
      "  ARIMA        | RMSE:   1.73% | Dir Acc:  58.2%\n",
      "  â Best: ARIMA (Dir Acc: 58.2%)\n",
      "\n",
      "[17/24] Training models for OXY...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 16:11:55,212 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 16:11:55,418 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:17:59,264 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "2025-10-09 16:17:59,430 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:18:02,600 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 16:18:02,687 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:18:05,730 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 16:18:05,781 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:18:06,046 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:18:06,099 - INFO - Training ARIMA...\n",
      "2025-10-09 16:18:06,409 - INFO - OXY: Selected XGBoost (Dir Acc=54.4%, RMSE=2.16%)\n",
      "2025-10-09 16:18:06,413 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.25% | Dir Acc:  54.4%\n",
      "  XGBoost      | RMSE:   2.16% | Dir Acc:  54.4%\n",
      "  MLP          | RMSE:   2.69% | Dir Acc:  49.4%\n",
      "  Lasso        | RMSE:   2.02% | Dir Acc:  48.1%\n",
      "  Ridge        | RMSE:   3.58% | Dir Acc:  48.1%\n",
      "  ARIMA        | RMSE:   2.02% | Dir Acc:  48.1%\n",
      "  â Best: XGBoost (Dir Acc: 54.4%)\n",
      "\n",
      "[18/24] Training models for PGJ...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 16:23:41,472 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 16:23:41,576 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:28:56,687 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 16:28:56,826 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:29:00,302 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 16:29:00,455 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:29:06,979 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 16:29:07,165 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:29:07,637 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:29:07,776 - INFO - Training ARIMA...\n",
      "2025-10-09 16:29:08,320 - INFO - PGJ: Selected Lasso (Dir Acc=55.7%, RMSE=1.41%)\n",
      "2025-10-09 16:29:08,323 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   2.11% | Dir Acc:  41.8%\n",
      "  XGBoost      | RMSE:   2.02% | Dir Acc:  53.2%\n",
      "  MLP          | RMSE:   2.40% | Dir Acc:  44.3%\n",
      "  Lasso        | RMSE:   1.41% | Dir Acc:  55.7%\n",
      "  Ridge        | RMSE:   2.28% | Dir Acc:  49.4%\n",
      "  ARIMA        | RMSE:   1.41% | Dir Acc:  55.7%\n",
      "  â Best: Lasso (Dir Acc: 55.7%)\n",
      "\n",
      "[19/24] Training models for RSP...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 16:34:35,834 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 16:34:36,052 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:39:19,714 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 16:39:19,827 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:39:24,633 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 16:39:24,730 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:39:29,292 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 16:39:29,407 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:39:29,757 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:39:29,874 - INFO - Training ARIMA...\n",
      "2025-10-09 16:39:30,154 - INFO - RSP: Selected MLP (Dir Acc=64.6%, RMSE=1.35%)\n",
      "2025-10-09 16:39:30,154 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.50% | Dir Acc:  48.1%\n",
      "  XGBoost      | RMSE:   0.90% | Dir Acc:  45.6%\n",
      "  MLP          | RMSE:   1.35% | Dir Acc:  64.6%\n",
      "  Lasso        | RMSE:   0.67% | Dir Acc:  53.2%\n",
      "  Ridge        | RMSE:   1.61% | Dir Acc:  54.4%\n",
      "  ARIMA        | RMSE:   0.67% | Dir Acc:  53.2%\n",
      "  â Best: MLP (Dir Acc: 64.6%)\n",
      "\n",
      "[20/24] Training models for SPY...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 16:45:04,801 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 16:45:05,061 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:49:35,362 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 16:49:35,475 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:49:40,167 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 16:49:40,238 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:49:45,193 - INFO - Best Lasso alpha: 0.1\n",
      "2025-10-09 16:49:45,299 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:49:45,593 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:49:45,716 - INFO - Training ARIMA...\n",
      "2025-10-09 16:49:46,115 - INFO - SPY: Selected ARIMA (Dir Acc=57.0%, RMSE=0.57%)\n",
      "2025-10-09 16:49:46,115 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.36% | Dir Acc:  51.9%\n",
      "  XGBoost      | RMSE:   2.66% | Dir Acc:  45.6%\n",
      "  MLP          | RMSE:   2.26% | Dir Acc:  44.3%\n",
      "  Lasso        | RMSE:   0.58% | Dir Acc:  54.4%\n",
      "  Ridge        | RMSE:   2.85% | Dir Acc:  41.8%\n",
      "  ARIMA        | RMSE:   0.57% | Dir Acc:  57.0%\n",
      "  â Best: ARIMA (Dir Acc: 57.0%)\n",
      "\n",
      "[21/24] Training models for TSLA...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 16:54:45,113 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 25}\n",
      "2025-10-09 16:54:45,236 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 16:59:31,585 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 16:59:31,695 - INFO - Training MLP with tuning...\n",
      "2025-10-09 16:59:33,777 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 16:59:33,810 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 16:59:38,150 - INFO - Best Lasso alpha: 10.0\n",
      "2025-10-09 16:59:38,268 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 16:59:38,536 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 16:59:38,594 - INFO - Training ARIMA...\n",
      "2025-10-09 16:59:38,844 - INFO - TSLA: Selected Lasso (Dir Acc=54.4%, RMSE=3.00%)\n",
      "2025-10-09 16:59:38,846 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   3.04% | Dir Acc:  51.9%\n",
      "  XGBoost      | RMSE:   3.03% | Dir Acc:  54.4%\n",
      "  MLP          | RMSE:   4.00% | Dir Acc:  48.1%\n",
      "  Lasso        | RMSE:   3.00% | Dir Acc:  54.4%\n",
      "  Ridge        | RMSE:   5.19% | Dir Acc:  48.1%\n",
      "  ARIMA        | RMSE:   3.00% | Dir Acc:  54.4%\n",
      "  â Best: Lasso (Dir Acc: 54.4%)\n",
      "\n",
      "[22/24] Training models for VGK...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 17:04:31,997 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 17:04:32,213 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 17:10:16,936 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 17:10:17,076 - INFO - Training MLP with tuning...\n",
      "2025-10-09 17:10:20,642 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 17:10:20,780 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 17:10:25,885 - INFO - Best Lasso alpha: 1.0\n",
      "2025-10-09 17:10:26,015 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 17:10:26,371 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 17:10:26,501 - INFO - Training ARIMA...\n",
      "2025-10-09 17:10:27,285 - INFO - VGK: Selected ARIMA (Dir Acc=55.7%, RMSE=0.78%)\n",
      "2025-10-09 17:10:27,287 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   1.00% | Dir Acc:  53.2%\n",
      "  XGBoost      | RMSE:   1.36% | Dir Acc:  45.6%\n",
      "  MLP          | RMSE:   1.92% | Dir Acc:  48.1%\n",
      "  Lasso        | RMSE:   0.78% | Dir Acc:  55.7%\n",
      "  Ridge        | RMSE:   2.39% | Dir Acc:  45.6%\n",
      "  ARIMA        | RMSE:   0.78% | Dir Acc:  55.7%\n",
      "  â Best: ARIMA (Dir Acc: 55.7%)\n",
      "\n",
      "[23/24] Training models for XPP...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 17:15:57,222 - INFO - Best RF params: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 25}\n",
      "2025-10-09 17:15:57,333 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 18:01:04,550 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2025-10-09 18:01:04,673 - INFO - Training MLP with tuning...\n",
      "2025-10-09 18:01:08,070 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.001}\n",
      "2025-10-09 18:01:08,154 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 18:01:11,773 - INFO - Best Lasso alpha: 10.0\n",
      "2025-10-09 18:01:11,875 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 18:01:12,188 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 18:01:12,261 - INFO - Training ARIMA...\n",
      "2025-10-09 18:01:12,674 - INFO - XPP: Selected Ridge (Dir Acc=54.4%, RMSE=4.59%)\n",
      "2025-10-09 18:01:12,674 - INFO - Training Random Forest with tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   3.60% | Dir Acc:  44.3%\n",
      "  XGBoost      | RMSE:   3.11% | Dir Acc:  43.0%\n",
      "  MLP          | RMSE:   2.75% | Dir Acc:  45.6%\n",
      "  Lasso        | RMSE:   2.25% | Dir Acc:  51.9%\n",
      "  Ridge        | RMSE:   4.59% | Dir Acc:  54.4%\n",
      "  ARIMA        | RMSE:   2.25% | Dir Acc:  51.9%\n",
      "  â Best: Ridge (Dir Acc: 54.4%)\n",
      "\n",
      "[24/24] Training models for YINN...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 18:07:36,776 - INFO - Best RF params: {'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 15}\n",
      "2025-10-09 18:07:37,042 - INFO - Training XGBoost with tuning...\n",
      "2025-10-09 18:13:08,102 - INFO - Best XGB params: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "2025-10-09 18:13:08,223 - INFO - Training MLP with tuning...\n",
      "2025-10-09 18:13:10,299 - INFO - Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "2025-10-09 18:13:10,406 - INFO - Training Lasso with tuning...\n",
      "2025-10-09 18:13:14,549 - INFO - Best Lasso alpha: 10.0\n",
      "2025-10-09 18:13:14,625 - INFO - Training Ridge with tuning...\n",
      "2025-10-09 18:13:14,948 - INFO - Best Ridge alpha: 100.0\n",
      "2025-10-09 18:13:15,011 - INFO - Training ARIMA...\n",
      "2025-10-09 18:13:15,612 - INFO - YINN: Selected Lasso (Dir Acc=51.9%, RMSE=3.38%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest | RMSE:   6.29% | Dir Acc:  43.0%\n",
      "  XGBoost      | RMSE:   4.95% | Dir Acc:  38.0%\n",
      "  MLP          | RMSE:   4.34% | Dir Acc:  45.6%\n",
      "  Lasso        | RMSE:   3.38% | Dir Acc:  51.9%\n",
      "  Ridge        | RMSE:   6.24% | Dir Acc:  51.9%\n",
      "  ARIMA        | RMSE:   3.39% | Dir Acc:  51.9%\n",
      "  â Best: Lasso (Dir Acc: 51.9%)\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TRAINING COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training enhanced models for all stocks with hyperparameter tuning...\")\n",
    "print(\"This will take 30-60 minutes depending on your CPU\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "enhanced_results = {}\n",
    "enhanced_summary = []\n",
    "\n",
    "for idx, (symbol, stock_data) in enumerate(enhanced_stock_data.items(), 1):\n",
    "    print(f\"\\n[{idx}/{len(enhanced_stock_data)}] Training models for {symbol}...\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    try:\n",
    "        results = enhanced_trainer.train_all_models(stock_data, quick_tune=True)\n",
    "        \n",
    "        if results:\n",
    "            enhanced_results[symbol] = results\n",
    "            \n",
    "            # Print performance\n",
    "            for model_type, data in results.items():\n",
    "                metrics = data['metrics']\n",
    "                print(f\"  {model_type:12s} | RMSE: {metrics['rmse']:6.2f}% | \"\n",
    "                      f\"Dir Acc: {metrics['directional_accuracy']:5.1f}%\")\n",
    "                \n",
    "                enhanced_summary.append({\n",
    "                    'symbol': symbol,\n",
    "                    'model': model_type,\n",
    "                    'rmse': metrics['rmse'],\n",
    "                    'dir_acc': metrics['directional_accuracy'],\n",
    "                    'has_sentiment': stock_data.get('has_sentiment', False)\n",
    "                })\n",
    "            \n",
    "            # Select best model\n",
    "            best = enhanced_trainer.select_best_model(symbol, results)\n",
    "            best_metrics = results[best]['metrics']\n",
    "            print(f\"  â Best: {best} (Dir Acc: {best_metrics['directional_accuracy']:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  â No models succeeded for {symbol}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  â Training failed: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENHANCED TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17105146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ENHANCED MODEL PERFORMANCE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Directional Accuracy by Model Type:\n",
      "----------------------------------------------------------------------\n",
      "               mean   std    min    max\n",
      "model                                  \n",
      "ARIMA         54.27  4.89  43.04  62.03\n",
      "Lasso         54.17  4.69  44.30  62.03\n",
      "MLP           49.47  6.81  41.77  64.56\n",
      "RandomForest  47.84  7.54  34.18  65.82\n",
      "Ridge         49.05  6.49  32.91  62.03\n",
      "XGBoost       47.42  5.87  34.18  60.76\n",
      "\n",
      "RMSE (%) by Model Type:\n",
      "----------------------------------------------------------------------\n",
      "               mean    std    min     max\n",
      "model                                    \n",
      "ARIMA         1.704  0.753  0.566   3.385\n",
      "Lasso         1.705  0.752  0.584   3.384\n",
      "MLP           2.628  1.067  1.280   5.055\n",
      "RandomForest  2.568  1.413  1.001   6.290\n",
      "Ridge         4.044  2.447  1.600  11.696\n",
      "XGBoost       2.474  1.229  0.902   5.764\n",
      "\n",
      "Top 5 Stocks by Directional Accuracy (Best Model):\n",
      "----------------------------------------------------------------------\n",
      "AAPL   | RandomForest | Dir Acc:  65.8% | RMSE:   1.52%\n",
      "JPM    | MLP          | Dir Acc:  64.6% | RMSE:   1.28%\n",
      "RSP    | MLP          | Dir Acc:  64.6% | RMSE:   1.35%\n",
      "CHN    | Lasso        | Dir Acc:  62.0% | RMSE:   1.57%\n",
      "ERO    | RandomForest | Dir Acc:  62.0% | RMSE:   2.86%\n",
      "\n",
      "Sentiment Impact:\n",
      "----------------------------------------------------------------------\n",
      "                dir_acc  rmse\n",
      "With Sentiment    50.37  2.52\n",
      "\n",
      "Stocks with sentiment data: 24\n",
      "Stocks without sentiment data: 0\n",
      "\n",
      "Enhanced Model Selection:\n",
      "----------------------------------------------------------------------\n",
      "Lasso_Enhanced                : 7 stocks\n",
      "Ridge_Enhanced                : 6 stocks\n",
      "ARIMA_Enhanced                : 4 stocks\n",
      "MLP_Enhanced                  : 4 stocks\n",
      "RandomForest_Enhanced         : 2 stocks\n",
      "XGBoost_Enhanced              : 1 stocks\n",
      "\n",
      "======================================================================\n",
      "KEY IMPROVEMENTS:\n",
      "======================================================================\n",
      "Average Directional Accuracy: 50.4% (Target: >55%)\n",
      "Average RMSE: 2.52%\n",
      "Models with >55% Dir Acc: 35 / 144\n",
      "\n",
      "â All enhanced models trained!\n",
      "â Model files saved in: enhanced_models/\n",
      "â Performance metrics saved to database\n",
      "\n",
      "If directional accuracy > 55%, ready for Week 4: Trading System!\n",
      "If still < 55%, we may need more feature engineering or longer sentiment history.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame(enhanced_summary)\n",
    "\n",
    "if not summary_df.empty:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENHANCED MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Average directional accuracy by model type\n",
    "    print(\"\\nDirectional Accuracy by Model Type:\")\n",
    "    print(\"-\"*70)\n",
    "    dir_acc_avg = summary_df.groupby('model')['dir_acc'].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(dir_acc_avg.round(2))\n",
    "    \n",
    "    # Average RMSE by model type\n",
    "    print(\"\\nRMSE (%) by Model Type:\")\n",
    "    print(\"-\"*70)\n",
    "    rmse_avg = summary_df.groupby('model')['rmse'].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(rmse_avg.round(3))\n",
    "    \n",
    "    # Best performers\n",
    "    print(\"\\nTop 5 Stocks by Directional Accuracy (Best Model):\")\n",
    "    print(\"-\"*70)\n",
    "    best_per_stock = summary_df.loc[summary_df.groupby('symbol')['dir_acc'].idxmax()]\n",
    "    top_stocks = best_per_stock.nlargest(5, 'dir_acc')[['symbol', 'model', 'dir_acc', 'rmse']]\n",
    "    for _, row in top_stocks.iterrows():\n",
    "        print(f\"{row['symbol']:6s} | {row['model']:12s} | \"\n",
    "              f\"Dir Acc: {row['dir_acc']:5.1f}% | RMSE: {row['rmse']:6.2f}%\")\n",
    "    \n",
    "    # Sentiment impact\n",
    "    print(\"\\nSentiment Impact:\")\n",
    "    print(\"-\"*70)\n",
    "    sentiment_comparison = summary_df.groupby('has_sentiment').agg({\n",
    "        'dir_acc': 'mean',\n",
    "        'rmse': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Safely rename index based on actual values\n",
    "    if len(sentiment_comparison) == 2:\n",
    "        sentiment_comparison.index = ['No Sentiment', 'With Sentiment']\n",
    "    elif len(sentiment_comparison) == 1:\n",
    "        has_sent = sentiment_comparison.index[0]\n",
    "        sentiment_comparison.index = ['With Sentiment' if has_sent else 'No Sentiment (All stocks)']\n",
    "    \n",
    "    print(sentiment_comparison)\n",
    "    \n",
    "    # Show distribution\n",
    "    sent_counts = summary_df.groupby('has_sentiment')['symbol'].nunique()\n",
    "    print(f\"\\nStocks with sentiment data: {sent_counts.get(True, 0)}\")\n",
    "    print(f\"Stocks without sentiment data: {sent_counts.get(False, 0)}\")\n",
    "    \n",
    "    # Model selection distribution\n",
    "    conn = mysql.connector.connect(**db_config)\n",
    "    selection_df = pd.read_sql(\"\"\"\n",
    "        SELECT symbol, selected_model_type, rmse, notes\n",
    "        FROM model_selection\n",
    "        WHERE selected_model_type LIKE '%Enhanced%'\n",
    "        ORDER BY rmse ASC\n",
    "    \"\"\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    if not selection_df.empty:\n",
    "        print(\"\\nEnhanced Model Selection:\")\n",
    "        print(\"-\"*70)\n",
    "        model_counts = selection_df['selected_model_type'].value_counts()\n",
    "        for model, count in model_counts.items():\n",
    "            print(f\"{model:30s}: {count} stocks\")\n",
    "    \n",
    "    # Overall improvement\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KEY IMPROVEMENTS:\")\n",
    "    print(\"=\"*70)\n",
    "    avg_dir_acc = summary_df['dir_acc'].mean()\n",
    "    avg_rmse = summary_df['rmse'].mean()\n",
    "    print(f\"Average Directional Accuracy: {avg_dir_acc:.1f}% (Target: >55%)\")\n",
    "    print(f\"Average RMSE: {avg_rmse:.2f}%\")\n",
    "    print(f\"Models with >55% Dir Acc: {(summary_df['dir_acc'] > 55).sum()} / {len(summary_df)}\")\n",
    "    \n",
    "    print(\"\\nâ All enhanced models trained!\")\n",
    "    print(f\"â Model files saved in: {enhanced_trainer.model_save_dir}/\")\n",
    "    print(\"â Performance metrics saved to database\")\n",
    "    print(\"\\nIf directional accuracy > 55%, ready for Week 4: Trading System!\")\n",
    "    print(\"If still < 55%, we may need more feature engineering or longer sentiment history.\")\n",
    "else:\n",
    "    print(\"No training summary available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
